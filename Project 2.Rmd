---
title: "Project 2: H-1B Visa"
author: "Spencer Stucky, Cheng Zeng, Wenyu Zeng, Chao Zhou"
date: "11/20/2019"
output:
  html_document:
    toc: yes
    toc_depth: 4
    fig.align: "center"
    toc_float: yes
    theme: readable
  pdf_document:
    toc: yes
    toc_depth: '4'
---

```{r setup, include=FALSE}
# some of common options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
knitr::opts_chunk$set(include = T)
# knitr::opts_chunk$set(echo = TRUE)
options(scientific=T, digits = 3) 
# options(scipen=9, digits = 3) 
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
```

```{r basicfcn, include=F}
# can add quietly=T option to the require() function
loadPkg = function(x) { if (!require(x,character.only=T, quietly =T)) { install.packages(x,dep=T,repos="http://cran.us.r-project.org"); if(!require(x,character.only=T)) stop("Package not found") } }
```

```{r, include=F}
h1b <- read.csv('h1b_new.csv')

str(h1b)

#h1b$State
```

```{r, include=F}
loadPkg("dplyr")
loadPkg("tidyr")
```
    
### Logistic Regression
```{r, echo=F}
h1b$Initial.Approvals <- as.factor(h1b$Initial.Approvals)
h1b$Initial.Denials <- as.factor(h1b$Initial.Denials)
h1b$Continuing.Approvals <- as.factor(h1b$Continuing.Approvals)
h1b$Continuing.Denials <- as.factor(h1b$Continuing.Denials)
h1b$NAICS <- as.factor(h1b$NAICS)
str(h1b)
```

```{r, echo=F}
IniApprLogit <- glm(Initial.Approvals ~ Fiscal.Year + NAICS + State, data = h1b, family = "binomial")
summary(IniApprLogit)
```

```{r, echo=F}
IniDenLogit <- glm(Initial.Denials ~ Fiscal.Year + NAICS + State, data = h1b, family = "binomial")
summary(IniDenLogit)
```

```{r, echo=F}
ConApprLogit <- glm(Continuing.Approvals ~ Fiscal.Year + NAICS + State, data = h1b, family = "binomial")
summary(ConApprLogit)
```

```{r, echo=F}
ConDenLogit <- glm(Continuing.Denials ~ Fiscal.Year + NAICS + State, data = h1b, family = "binomial")
summary(ConDenLogit)
```



### Try Tree Model
```{r}
loadPkg("rpart") # Classification trees, rpart(formula, data=, method=,control=) 
```

```{r, echo = T, fig.dim=c(6,4)}
treefit <- rpart(Initial.Approvals ~ Fiscal.Year + State + NAICS,
  	method="class", data=h1b)

printcp(treefit) # display the results 
plotcp(treefit) # visualize cross-validation results 
summary(treefit) # detailed summary of splits

# plot tree 
plot(treefit, uniform=TRUE, main="Classification Tree for H1B")
text(treefit, use.n=TRUE, all=TRUE, cex=.8)

```


```{r}
# create attractive postcript plot of tree 
post(treefit, file = "kythosisTree2.ps", title = "Classification Tree for H1B")
```



### Try KNN
```{r}
# convert NAICS to binary based on mean of applicantsis
is.na(h1b)
h1bcopy <- drop_na(h1b)
nrow(h1bcopy)/25
h1bN <- h1bcopy %>% group_by(NAICS)
h1bN
```

```{r, echo=F}
IniApprLogit <- glm(Initial.Approvals ~ Fiscal.Year + NAICS + State, data = h1bcopy, family = "binomial")
summary(IniApprLogit)
```

```{r}
h1b$NAICS <- as.character(h1b$NAICS)
set.seed(1)
h1b_data_train_rows = sample(1:nrow(h1b),     #<- from 1 to the number of 
                                                     #   rows in the data set
                              round(0.8 * nrow(h1b), 0),  #<- multiply the 
                                                                #   number of rows
                                                                #   by 0.8 and round
                                                                #   the decimals
                              replace = FALSE)       #<- don't replace the numbers

# Let's check to make sure we have 80% of the rows. 
length(h1b_data_train_rows) / nrow(h1b)

h1b_data_train = h1b[h1b_data_train_rows, ]  #<- select the rows identified in
                                                     #   the bank_data_train_rows data
h1b_data_test = h1b[-h1b_data_train_rows, ]  #<- select the rows that weren't
                                                     #   identified in the

head(h1b_data_test)                                          
```

```{r}
loadPkg("class")

# k-Nearest Neighbor is a randomized algorithm, so make sure to
# use set.seed() to make your results repeatable.
set.seed(1)
# h1b$Initial.Approvals <- NULL
#h1b$NAICS <- as.integer(h1b$NAICS)
#str(h1b)
h1b_3NN = knn(train = h1b_data_train[, c("State", "NAICS")],  #<- training set cases
               test = h1b_data_test[, c("State","NAICS")],    #<- test set cases
               cl = h1b_data_train[, "Initial.Approvals"],                  #<- category for true classification
               k = 3) #,                                                    #<- number of neighbors considered
               #use.all = TRUE)                                            #<- control ties between class assignments
                                                                            #   If true, all distances equal to the kth 
                                                                            #   largest are included

# View the output.
str(h1b_3NN)
length(h1b_3NN)
table(h1b_3NN)
```

```{r}
kNN_res = table(h1b_3NN,
                h1b_data_test$`Initial.Approvals`)
kNN_res
sum(kNN_res)  #<- the total is all the test examples

# Select the true positives and true negatives by selecting
# only the cells where the row and column names are the same.
kNN_res[row(kNN_res) == col(kNN_res)]

# Calculate the accuracy rate by dividing the correct classifications
# by the total number of classifications.
kNN_acc = sum(kNN_res[row(kNN_res) == col(kNN_res)]) / sum(kNN_res)
kNN_acc
```

